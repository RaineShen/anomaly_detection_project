{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY4SK0xKAJgm"
   },
   "source": [
    "# RNN with LSTM with Log Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc6xejhY-NzZ"
   },
   "source": [
    "In this lab one will use log CSV text dataset for training a simple RNN for sentiment classification (here: a binary classification problem with two labels, annomally and normal) using LSTM (Long Short Term Memory) cells and GRU Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "moNmVfuvnImW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchtext.legacy import data\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from torchtext import datasets\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSRL42Qgy8I8"
   },
   "source": [
    "## General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OvW1RgfepCBq"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "VOCABULARY_SIZE = 20000\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 15\n",
    "EMBEDDING_DIM = 128 #128\n",
    "HIDDEN_DIM = 328 #256\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQMmKUEisW4W"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo7JEXr0KFqC"
   },
   "source": [
    "Check that the dataset looks okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1d-pABVbKFqC"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/content/drive/MyDrive/Lab 4/movie_data.csv')\n",
    "# df.head()\n",
    "\n",
    "#log= pd.read_csv('/content/drive/MyDrive/586_project_NPL/unique_id.csv')\n",
    "log= pd.read_csv('/Users/yuxuancui/Desktop/MDS/data586/project/rnn/log_rnn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "naC8d2TjXhC9",
    "outputId": "1af7929c-5d7a-463e-f51f-99348fc57026"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Content_npl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>BLOCK NameSystem allocateBlock user root sortr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Receiving block blk src dest Receiving block b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>BLOCK NameSystem allocateBlock user root randt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>BLOCK NameSystem allocateBlock user root rand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Receiving block blk src dest BLOCK NameSystem ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                        Content_npl\n",
       "0  Normal  BLOCK NameSystem allocateBlock user root sortr...\n",
       "1  Normal  Receiving block blk src dest Receiving block b...\n",
       "2  Normal  BLOCK NameSystem allocateBlock user root randt...\n",
       "3  Normal  BLOCK NameSystem allocateBlock user root rand ...\n",
       "4  Normal  Receiving block blk src dest BLOCK NameSystem ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gLlL6UVKFqC"
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GnH64XvsV8n"
   },
   "source": [
    "Define the Label and Text field formatters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (3.0.0)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.4)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /Users/yuxuancui/.local/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (51.0.0)\n",
      "Requirement already satisfied: jinja2 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.46.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: six in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/yuxuancui/opt/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MisRpSsqKFqD"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,\n",
    "                  #tokenize='spacy',\n",
    "                  include_lengths=True) # necessary for packed_padded_sequence\n",
    "\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPYH5c6HKFqD"
   },
   "source": [
    "Process the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8168UtAbKFqD"
   },
   "outputs": [],
   "source": [
    "fields = [('Label', LABEL),('Content_npl', TEXT)]\n",
    "\n",
    "dataset = data.TabularDataset(\n",
    "    path='/Users/yuxuancui/Desktop/MDS/data586/project/rnn/log_rnn.csv', format='csv',\n",
    "    skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS1ULp5-KFqE"
   },
   "source": [
    "Split the dataset into training, validation, and test partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZ_4jiHVnMxN",
    "outputId": "811bcc93-e095-448c-fa48-82f1dc0ea2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 431296\n",
      "Num Valid: 115012\n",
      "Num Test: 28753\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.split(\n",
    "    split_ratio=[0.75, 0.05, 0.2],\n",
    "    random_state=random.seed(RANDOM_SEED))\n",
    "#One may want to vary the test, train split percentages\n",
    "print(f'Num Train: {len(train_data)}')\n",
    "print(f'Num Valid: {len(valid_data)}')\n",
    "print(f'Num Test: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-TBwKWPslPa"
   },
   "source": [
    "Build the vocabulary based on the top \"VOCABULARY_SIZE\" words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8uNrjdtn4A8",
    "outputId": "fa4ecc41-dda6-405a-96ad-a1486d1bc380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 201\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8KpevWxKFqF",
    "outputId": "d0996d3d-784c-4782-c843-33d5e198f267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' ': 327,\n",
       "         'BLOCK': 19192,\n",
       "         'Could': 39,\n",
       "         'Deleting': 8,\n",
       "         'EOFException': 1,\n",
       "         'Exception': 1,\n",
       "         'IOException': 39,\n",
       "         'NameSystem': 19180,\n",
       "         'PacketResponder': 14119,\n",
       "         'Received': 14190,\n",
       "         'Receiving': 15063,\n",
       "         'Served': 303,\n",
       "         'SocketTimeoutException': 1,\n",
       "         'Starting': 15,\n",
       "         'Transmitted': 9,\n",
       "         'Verification': 681,\n",
       "         'addStoredBlock': 14105,\n",
       "         'added': 14105,\n",
       "         'allocateBlock': 5075,\n",
       "         'ask': 12,\n",
       "         'blk': 63628,\n",
       "         'block': 43706,\n",
       "         'blockMap': 14105,\n",
       "         'conf': 1,\n",
       "         'current': 8,\n",
       "         'data': 8,\n",
       "         'datanode': 12,\n",
       "         'dest': 15067,\n",
       "         'dfs': 8,\n",
       "         'ec': 1,\n",
       "         'empty': 9,\n",
       "         'exception': 40,\n",
       "         'file': 8,\n",
       "         'for': 14808,\n",
       "         'from': 14216,\n",
       "         'hadoop': 10,\n",
       "         'history': 1,\n",
       "         'internal': 1,\n",
       "         'io': 40,\n",
       "         'ip': 1,\n",
       "         'is': 14105,\n",
       "         'jar': 1,\n",
       "         'java': 41,\n",
       "         'job': 5,\n",
       "         'logs': 1,\n",
       "         'm': 5072,\n",
       "         'mapred': 2,\n",
       "         'mnt': 10,\n",
       "         'net': 1,\n",
       "         'not': 39,\n",
       "         'of': 14190,\n",
       "         'packet': 9,\n",
       "         'part': 5072,\n",
       "         'rand': 5073,\n",
       "         'read': 39,\n",
       "         'received': 40,\n",
       "         'replicate': 12,\n",
       "         'root': 5073,\n",
       "         's': 12,\n",
       "         'size': 28295,\n",
       "         'split': 1,\n",
       "         'src': 15067,\n",
       "         'stream': 39,\n",
       "         'subdir': 8,\n",
       "         'succeeded': 681,\n",
       "         'system': 2,\n",
       "         'task': 5072,\n",
       "         'temporary': 5072,\n",
       "         'terminating': 14118,\n",
       "         'thread': 15,\n",
       "         'to': 14471,\n",
       "         'transfer': 15,\n",
       "         'updated': 14105,\n",
       "         'user': 5073,\n",
       "         'writeBlock': 40,\n",
       "         'xml': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.freqs\n",
    "TEXT.vocab.freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpEMNInXtZsb"
   },
   "source": [
    "The TEXT.vocab dictionary will contain the word counts and indices. The reason why the number of words is VOCABULARY_SIZE + 2 is that it contains to special tokens for padding and unknown words: `<unk>` and `<pad>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIQ_zfKLwjKm"
   },
   "source": [
    "Make dataset iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "i7JiHR1stHNF"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True, # necessary for packed_padded_sequence\n",
    "    sort_key=lambda x: len(x.Content_npl),\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0pT_dMRvicQ"
   },
   "source": [
    "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8SP_FccutT0",
    "outputId": "00f2d824-2340-4548-a71d-bea7589806c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Text matrix size: torch.Size([146, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Valid:\n",
      "Text matrix size: torch.Size([16, 128])\n",
      "Target vector size: torch.Size([128])\n",
      "\n",
      "Test:\n",
      "Text matrix size: torch.Size([16, 128])\n",
      "Target vector size: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.Content_npl[0].size()}')\n",
    "    print(f'Target vector size: {batch.Label.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nValid:')\n",
    "for batch in valid_loader:\n",
    "    print(f'Text matrix size: {batch.Content_npl[0].size()}')\n",
    "    print(f'Target vector size: {batch.Label.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.Content_npl[0].size()}')\n",
    "    print(f'Target vector size: {batch.Label.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_grdW3pxCzz"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuDKXDCMKFqG"
   },
   "source": [
    " ### The primary goal of this lab is to vary the hyperparameters of the LSTM model and see the results and provide analysis\n",
    " ### The second task is to use a another RNN cell such as GRU and perform parameter tuning and report the results.\n",
    " \n",
    " ### The remainder of the code will have to be modified accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nQIUm5EjxFNa"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        #Here is a preliminary model using LSTM cell\n",
    "        #The primary goal of this lab is to vary the dimensions of the embeddings and see the results\n",
    "        #The second task is to use a another RNN cell such as GRU and perform parameter tuning and report the results.\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_length):\n",
    "\n",
    "        #[sentence len, batch size] => [sentence len, batch size, embedding size]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, text_length)\n",
    "      \n",
    "        #[sentence len, batch size, embedding size] => \n",
    "        #  output: [sentence len, batch size, hidden size]\n",
    "        #  hidden: [1, batch size, hidden size]\n",
    "        packed_output, (hidden, cell) = self.rnn(packed)\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ik3NF3faxFmZ"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv9Ny9di6VcI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T5t1Afn4xO11"
   },
   "outputs": [],
   "source": [
    "def compute_binary_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(data_loader):\n",
    "            text, text_lengths = batch_data.Content_npl\n",
    "            logits = model(text, text_lengths.cpu())\n",
    "            predicted_labels = (torch.sigmoid(logits) > 0.5).long()\n",
    "            num_examples += batch_data.Label.size(0)\n",
    "            correct_pred += (predicted_labels.long() == batch_data.Label.long()).sum()\n",
    "        return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EABZM8Vo0ilB",
    "outputId": "ccddc496-71a6-40a2-a4a8-4d90a9457ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 000/498 | Cost: 0.7357\n",
      "Epoch: 001/015 | Batch 050/498 | Cost: 0.3297\n",
      "Epoch: 001/015 | Batch 100/498 | Cost: 0.1690\n",
      "Epoch: 001/015 | Batch 150/498 | Cost: 0.1873\n",
      "Epoch: 001/015 | Batch 200/498 | Cost: 0.1004\n",
      "Epoch: 001/015 | Batch 250/498 | Cost: 0.1630\n",
      "Epoch: 001/015 | Batch 300/498 | Cost: 0.1092\n",
      "Epoch: 001/015 | Batch 350/498 | Cost: 0.1359\n",
      "Epoch: 001/015 | Batch 400/498 | Cost: 0.1112\n",
      "Epoch: 001/015 | Batch 450/498 | Cost: 0.1662\n",
      "training accuracy: 97.23%\n",
      "valid accuracy: 97.31%\n",
      "Time elapsed: 0.05 min\n",
      "Epoch: 002/015 | Batch 000/498 | Cost: 0.1117\n",
      "Epoch: 002/015 | Batch 050/498 | Cost: 0.1970\n",
      "Epoch: 002/015 | Batch 100/498 | Cost: 0.0622\n",
      "Epoch: 002/015 | Batch 150/498 | Cost: 0.1640\n",
      "Epoch: 002/015 | Batch 200/498 | Cost: 0.1751\n",
      "Epoch: 002/015 | Batch 250/498 | Cost: 0.1989\n",
      "Epoch: 002/015 | Batch 300/498 | Cost: 0.2042\n",
      "Epoch: 002/015 | Batch 350/498 | Cost: 0.1363\n",
      "Epoch: 002/015 | Batch 400/498 | Cost: 0.1100\n",
      "Epoch: 002/015 | Batch 450/498 | Cost: 0.1713\n",
      "training accuracy: 97.23%\n",
      "valid accuracy: 97.31%\n",
      "Time elapsed: 0.09 min\n",
      "Epoch: 003/015 | Batch 000/498 | Cost: 0.0696\n",
      "Epoch: 003/015 | Batch 050/498 | Cost: 0.0495\n",
      "Epoch: 003/015 | Batch 100/498 | Cost: 0.1265\n",
      "Epoch: 003/015 | Batch 150/498 | Cost: 0.1349\n",
      "Epoch: 003/015 | Batch 200/498 | Cost: 0.1421\n",
      "Epoch: 003/015 | Batch 250/498 | Cost: 0.1673\n",
      "Epoch: 003/015 | Batch 300/498 | Cost: 0.2417\n",
      "Epoch: 003/015 | Batch 350/498 | Cost: 0.1827\n",
      "Epoch: 003/015 | Batch 400/498 | Cost: 0.1071\n",
      "Epoch: 003/015 | Batch 450/498 | Cost: 0.0178\n",
      "training accuracy: 97.23%\n",
      "valid accuracy: 97.25%\n",
      "Time elapsed: 0.13 min\n",
      "Epoch: 004/015 | Batch 000/498 | Cost: 0.2261\n",
      "Epoch: 004/015 | Batch 050/498 | Cost: 0.1397\n",
      "Epoch: 004/015 | Batch 100/498 | Cost: 0.1400\n",
      "Epoch: 004/015 | Batch 150/498 | Cost: 0.0481\n",
      "Epoch: 004/015 | Batch 200/498 | Cost: 0.1115\n",
      "Epoch: 004/015 | Batch 250/498 | Cost: 0.1149\n",
      "Epoch: 004/015 | Batch 300/498 | Cost: 0.0885\n",
      "Epoch: 004/015 | Batch 350/498 | Cost: 0.0715\n",
      "Epoch: 004/015 | Batch 400/498 | Cost: 0.0548\n",
      "Epoch: 004/015 | Batch 450/498 | Cost: 0.1121\n",
      "training accuracy: 97.23%\n",
      "valid accuracy: 97.25%\n",
      "Time elapsed: 0.18 min\n",
      "Epoch: 005/015 | Batch 000/498 | Cost: 0.1392\n",
      "Epoch: 005/015 | Batch 050/498 | Cost: 0.1402\n",
      "Epoch: 005/015 | Batch 100/498 | Cost: 0.1152\n",
      "Epoch: 005/015 | Batch 150/498 | Cost: 0.0256\n",
      "Epoch: 005/015 | Batch 200/498 | Cost: 0.1098\n",
      "Epoch: 005/015 | Batch 250/498 | Cost: 0.1396\n",
      "Epoch: 005/015 | Batch 300/498 | Cost: 0.1757\n",
      "Epoch: 005/015 | Batch 350/498 | Cost: 0.0807\n",
      "Epoch: 005/015 | Batch 400/498 | Cost: 0.0818\n",
      "Epoch: 005/015 | Batch 450/498 | Cost: 0.1724\n",
      "training accuracy: 97.24%\n",
      "valid accuracy: 97.25%\n",
      "Time elapsed: 0.22 min\n",
      "Epoch: 006/015 | Batch 000/498 | Cost: 0.2324\n",
      "Epoch: 006/015 | Batch 050/498 | Cost: 0.1950\n",
      "Epoch: 006/015 | Batch 100/498 | Cost: 0.1760\n",
      "Epoch: 006/015 | Batch 150/498 | Cost: 0.1152\n",
      "Epoch: 006/015 | Batch 200/498 | Cost: 0.1626\n",
      "Epoch: 006/015 | Batch 250/498 | Cost: 0.0805\n",
      "Epoch: 006/015 | Batch 300/498 | Cost: 0.0698\n",
      "Epoch: 006/015 | Batch 350/498 | Cost: 0.1978\n",
      "Epoch: 006/015 | Batch 400/498 | Cost: 0.1203\n",
      "Epoch: 006/015 | Batch 450/498 | Cost: 0.1915\n",
      "training accuracy: 97.25%\n",
      "valid accuracy: 97.27%\n",
      "Time elapsed: 0.27 min\n",
      "Epoch: 007/015 | Batch 000/498 | Cost: 0.1921\n",
      "Epoch: 007/015 | Batch 050/498 | Cost: 0.1134\n",
      "Epoch: 007/015 | Batch 100/498 | Cost: 0.1114\n",
      "Epoch: 007/015 | Batch 150/498 | Cost: 0.0501\n",
      "Epoch: 007/015 | Batch 200/498 | Cost: 0.1188\n",
      "Epoch: 007/015 | Batch 250/498 | Cost: 0.1427\n",
      "Epoch: 007/015 | Batch 300/498 | Cost: 0.1786\n",
      "Epoch: 007/015 | Batch 350/498 | Cost: 0.0539\n",
      "Epoch: 007/015 | Batch 400/498 | Cost: 0.0849\n",
      "Epoch: 007/015 | Batch 450/498 | Cost: 0.1166\n",
      "training accuracy: 97.25%\n",
      "valid accuracy: 97.34%\n",
      "Time elapsed: 0.31 min\n",
      "Epoch: 008/015 | Batch 000/498 | Cost: 0.0646\n",
      "Epoch: 008/015 | Batch 050/498 | Cost: 0.1114\n",
      "Epoch: 008/015 | Batch 100/498 | Cost: 0.1402\n",
      "Epoch: 008/015 | Batch 150/498 | Cost: 0.0821\n",
      "Epoch: 008/015 | Batch 200/498 | Cost: 0.1125\n",
      "Epoch: 008/015 | Batch 250/498 | Cost: 0.1443\n",
      "Epoch: 008/015 | Batch 300/498 | Cost: 0.1425\n",
      "Epoch: 008/015 | Batch 350/498 | Cost: 0.2024\n",
      "Epoch: 008/015 | Batch 400/498 | Cost: 0.2355\n",
      "Epoch: 008/015 | Batch 450/498 | Cost: 0.0134\n",
      "training accuracy: 97.26%\n",
      "valid accuracy: 97.34%\n",
      "Time elapsed: 0.36 min\n",
      "Epoch: 009/015 | Batch 000/498 | Cost: 0.0485\n",
      "Epoch: 009/015 | Batch 050/498 | Cost: 0.1240\n",
      "Epoch: 009/015 | Batch 100/498 | Cost: 0.2028\n",
      "Epoch: 009/015 | Batch 150/498 | Cost: 0.1935\n",
      "Epoch: 009/015 | Batch 200/498 | Cost: 0.1994\n",
      "Epoch: 009/015 | Batch 250/498 | Cost: 0.1763\n",
      "Epoch: 009/015 | Batch 300/498 | Cost: 0.2063\n",
      "Epoch: 009/015 | Batch 350/498 | Cost: 0.0560\n",
      "Epoch: 009/015 | Batch 400/498 | Cost: 0.0498\n",
      "Epoch: 009/015 | Batch 450/498 | Cost: 0.0839\n",
      "training accuracy: 97.29%\n",
      "valid accuracy: 97.29%\n",
      "Time elapsed: 0.40 min\n",
      "Epoch: 010/015 | Batch 000/498 | Cost: 0.1400\n",
      "Epoch: 010/015 | Batch 050/498 | Cost: 0.0603\n",
      "Epoch: 010/015 | Batch 100/498 | Cost: 0.0520\n",
      "Epoch: 010/015 | Batch 150/498 | Cost: 0.1111\n",
      "Epoch: 010/015 | Batch 200/498 | Cost: 0.1381\n",
      "Epoch: 010/015 | Batch 250/498 | Cost: 0.0815\n",
      "Epoch: 010/015 | Batch 300/498 | Cost: 0.0809\n",
      "Epoch: 010/015 | Batch 350/498 | Cost: 0.1689\n",
      "Epoch: 010/015 | Batch 400/498 | Cost: 0.1447\n",
      "Epoch: 010/015 | Batch 450/498 | Cost: 0.1504\n",
      "training accuracy: 97.29%\n",
      "valid accuracy: 97.29%\n",
      "Time elapsed: 0.44 min\n",
      "Epoch: 011/015 | Batch 000/498 | Cost: 0.1141\n",
      "Epoch: 011/015 | Batch 050/498 | Cost: 0.0857\n",
      "Epoch: 011/015 | Batch 100/498 | Cost: 0.0779\n",
      "Epoch: 011/015 | Batch 150/498 | Cost: 0.0492\n",
      "Epoch: 011/015 | Batch 200/498 | Cost: 0.1807\n",
      "Epoch: 011/015 | Batch 250/498 | Cost: 0.0815\n",
      "Epoch: 011/015 | Batch 300/498 | Cost: 0.0942\n",
      "Epoch: 011/015 | Batch 350/498 | Cost: 0.1445\n",
      "Epoch: 011/015 | Batch 400/498 | Cost: 0.0492\n",
      "Epoch: 011/015 | Batch 450/498 | Cost: 0.1117\n",
      "training accuracy: 97.28%\n",
      "valid accuracy: 97.35%\n",
      "Time elapsed: 0.49 min\n",
      "Epoch: 012/015 | Batch 000/498 | Cost: 0.0805\n",
      "Epoch: 012/015 | Batch 050/498 | Cost: 0.0504\n",
      "Epoch: 012/015 | Batch 100/498 | Cost: 0.1161\n",
      "Epoch: 012/015 | Batch 150/498 | Cost: 0.0810\n",
      "Epoch: 012/015 | Batch 200/498 | Cost: 0.2265\n",
      "Epoch: 012/015 | Batch 250/498 | Cost: 0.1399\n",
      "Epoch: 012/015 | Batch 300/498 | Cost: 0.0818\n",
      "Epoch: 012/015 | Batch 350/498 | Cost: 0.1111\n",
      "Epoch: 012/015 | Batch 400/498 | Cost: 0.2336\n",
      "Epoch: 012/015 | Batch 450/498 | Cost: 0.0543\n",
      "training accuracy: 97.28%\n",
      "valid accuracy: 97.35%\n",
      "Time elapsed: 0.53 min\n",
      "Epoch: 013/015 | Batch 000/498 | Cost: 0.0870\n",
      "Epoch: 013/015 | Batch 050/498 | Cost: 0.2274\n",
      "Epoch: 013/015 | Batch 100/498 | Cost: 0.1120\n",
      "Epoch: 013/015 | Batch 150/498 | Cost: 0.1533\n",
      "Epoch: 013/015 | Batch 200/498 | Cost: 0.0809\n",
      "Epoch: 013/015 | Batch 250/498 | Cost: 0.0232\n",
      "Epoch: 013/015 | Batch 300/498 | Cost: 0.1118\n",
      "Epoch: 013/015 | Batch 350/498 | Cost: 0.0821\n",
      "Epoch: 013/015 | Batch 400/498 | Cost: 0.0836\n",
      "Epoch: 013/015 | Batch 450/498 | Cost: 0.1417\n",
      "training accuracy: 97.28%\n",
      "valid accuracy: 97.35%\n",
      "Time elapsed: 0.58 min\n",
      "Epoch: 014/015 | Batch 000/498 | Cost: 0.1273\n",
      "Epoch: 014/015 | Batch 050/498 | Cost: 0.1411\n",
      "Epoch: 014/015 | Batch 100/498 | Cost: 0.0568\n",
      "Epoch: 014/015 | Batch 150/498 | Cost: 0.0830\n",
      "Epoch: 014/015 | Batch 200/498 | Cost: 0.0845\n",
      "Epoch: 014/015 | Batch 250/498 | Cost: 0.0862\n",
      "Epoch: 014/015 | Batch 300/498 | Cost: 0.2285\n",
      "Epoch: 014/015 | Batch 350/498 | Cost: 0.1224\n",
      "Epoch: 014/015 | Batch 400/498 | Cost: 0.0405\n",
      "Epoch: 014/015 | Batch 450/498 | Cost: 0.0822\n",
      "training accuracy: 97.29%\n",
      "valid accuracy: 97.29%\n",
      "Time elapsed: 0.62 min\n",
      "Epoch: 015/015 | Batch 000/498 | Cost: 0.1407\n",
      "Epoch: 015/015 | Batch 050/498 | Cost: 0.1098\n",
      "Epoch: 015/015 | Batch 100/498 | Cost: 0.1437\n",
      "Epoch: 015/015 | Batch 150/498 | Cost: 0.1429\n",
      "Epoch: 015/015 | Batch 200/498 | Cost: 0.0212\n",
      "Epoch: 015/015 | Batch 250/498 | Cost: 0.1311\n",
      "Epoch: 015/015 | Batch 300/498 | Cost: 0.1675\n",
      "Epoch: 015/015 | Batch 350/498 | Cost: 0.2053\n",
      "Epoch: 015/015 | Batch 400/498 | Cost: 0.1129\n",
      "Epoch: 015/015 | Batch 450/498 | Cost: 0.1409\n",
      "training accuracy: 97.29%\n",
      "valid accuracy: 97.29%\n",
      "Time elapsed: 0.67 min\n",
      "Total Training Time: 0.67 min\n",
      "Test accuracy: 97.69%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        \n",
    "        text, text_lengths = batch_data.Content_npl\n",
    "        \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits = model(text, text_lengths.cpu())\n",
    "        cost = F.binary_cross_entropy_with_logits(logits, batch_data.Label)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Cost: {cost:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_binary_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_binary_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "        \n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_binary_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jt55pscgFdKZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    # based on:\n",
    "    # https://github.com/bentrevett/pytorch-sentiment-analysis/blob/\n",
    "    # master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "xq2yV5z7LkAI"
   },
   "outputs": [],
   "source": [
    "# testing set \n",
    "\n",
    "test_2k=pd.read_csv('/content/drive/MyDrive/586_project_NPL/test_2k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "q2cwX0HQbcMe"
   },
   "outputs": [],
   "source": [
    "test=test_2k[['BlockId','Full_Event_Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "aYUiS1LChLAS",
    "outputId": "073bb0d0-bc34-4cf7-ad70-f28e9425d58f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Full_Event_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38865049064139660</td>\n",
       "      <td>PacketResponder for block blk terminating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6952295868487656571</td>\n",
       "      <td>PacketResponder for block blk terminating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7128370237687728475</td>\n",
       "      <td>BLOCK NameSystem addStoredBlock blockMap updat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8229193803249955061</td>\n",
       "      <td>PacketResponder for block blk terminating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6670958622368987959</td>\n",
       "      <td>PacketResponder for block blk terminating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>4198733391373026104</td>\n",
       "      <td>Receiving block blk src dest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>5815145248455404269</td>\n",
       "      <td>Received block blk of size from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>295306975763175640</td>\n",
       "      <td>Receiving block blk src dest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>5225719677049010638</td>\n",
       "      <td>PacketResponder for block blk terminating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>4343207286455274569</td>\n",
       "      <td>Receiving block blk src dest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  BlockId                             Full_Event_Description\n",
       "0       38865049064139660          PacketResponder for block blk terminating\n",
       "1     6952295868487656571          PacketResponder for block blk terminating\n",
       "2     7128370237687728475  BLOCK NameSystem addStoredBlock blockMap updat...\n",
       "3     8229193803249955061          PacketResponder for block blk terminating\n",
       "4     6670958622368987959          PacketResponder for block blk terminating\n",
       "...                   ...                                                ...\n",
       "1995  4198733391373026104                      Receiving block blk src dest \n",
       "1996  5815145248455404269                   Received block blk of size from \n",
       "1997   295306975763175640                      Receiving block blk src dest \n",
       "1998  5225719677049010638          PacketResponder for block blk terminating\n",
       "1999  4343207286455274569                      Receiving block blk src dest \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_7wBScLgzn-",
    "outputId": "f9f2b518-d88f-41b8-ed88-a43869e6f816"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlockId                                    7517964792804498202\n",
       "Full_Event_Description     Got exception while serving blk to \n",
       "Name: 100, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4__q0coFJyw",
    "outputId": "56126e7c-997a-42ea-d128-78073c9c9e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability anomaly:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5205644965171814"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Probability anomaly:')\n",
    "1-predict_sentiment(model, \"Got exception while serving blk to \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "c4TFKixKKFqJ"
   },
   "outputs": [],
   "source": [
    "Prob=[]\n",
    "for line in test.Full_Event_Description:\n",
    "  p=1-predict_sentiment(model,line)\n",
    "  Prob.append(p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "EZETRNzKdCFY"
   },
   "outputs": [],
   "source": [
    "Label=[]\n",
    "\n",
    "for i in Prob:\n",
    "  if i>0.5:\n",
    "    Label.append(\"Anomaly\")\n",
    "  else:\n",
    "    Label.append(\"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8FUw24HeKij",
    "outputId": "fde73c90-95a9-4f2c-ac2c-6079fd654666"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test[\"Label\"]=Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kESHrGK7fNML",
    "outputId": "b3027702-1c3e-4349-e63c-1403d3ddfb89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anomaly    1573\n",
       "Normal      427\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(Label)[\"Label\"].count()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN_project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
